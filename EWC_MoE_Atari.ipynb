{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2e297f",
   "metadata": {},
   "source": [
    "# EWC + MoE Router (RNN) Multi-Atari: Day/Night Training (Gymnasium)\n",
    "\n",
    "This notebook is a **Colab-friendly scaffold** to test a hypothesis:\n",
    "\n",
    "- You can train in a correlated **online** stream (\"day\") but do most SGD updates during a shuffled **replay** phase (\"sleep\").\n",
    "- Long-term retention is handled via **Elastic Weight Consolidation (EWC)** on shared parameters (router / trunk and optionally per-game experts).\n",
    "- Capacity and out-of-core motivation: a **shared recurrent router** gates a set of **experts** (MoE), which you can later swap across HBM/DRAM/NVMe.\n",
    "\n",
    "**Practical constraints handled here:**\n",
    "- Gymnasium (modern API)\n",
    "- Atari preprocessing via `AtariPreprocessing`\n",
    "- Frame stacking via `FrameStackObservation` (FrameStack is deprecated in Gymnasium v1+)\n",
    "- Unified action space using `full_action_space=True` (Discrete(18) across games)\n",
    "- Reward clipping to `[-1, 1]`\n",
    "\n",
    "> This is a *smoke test* configuration by default (few thousand steps). Atari at scale is expensive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ec1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install deps (Colab)\n",
    "!pip -q install -U 'gymnasium[atari]' ale-py opencv-python 'torch>=2.1.0' 'torchvision>=0.16.0'\n",
    "\n",
    "import gymnasium\n",
    "print('Gymnasium version:', gymnasium.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa426f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this repository's src/ to PYTHONPATH\n",
    "import os, sys\n",
    "\n",
    "# If you uploaded the zip to Colab and unzipped it, set PROJECT_DIR accordingly.\n",
    "# For example:\n",
    "#   PROJECT_DIR = '/content/ewc_moe_atari_colab'\n",
    "# Here we assume the notebook is in the project root.\n",
    "PROJECT_DIR = os.getcwd()\n",
    "SRC_DIR = os.path.join(PROJECT_DIR, 'src')\n",
    "\n",
    "# Check if we are potentially in the wrong directory\n",
    "if not os.path.exists(SRC_DIR):\n",
    "    print(f\"Warning: 'src' directory not found at {SRC_DIR}.\")\n",
    "    print(\"Please ensure you are running this notebook from the project root or set PROJECT_DIR correctly.\")\n",
    "else:\n",
    "    if SRC_DIR not in sys.path:\n",
    "        sys.path.append(SRC_DIR)\n",
    "    print('PROJECT_DIR:', PROJECT_DIR)\n",
    "    print('SRC_DIR:', SRC_DIR)\n",
    "    print('Added src to sys.path')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick env smoke test\n",
    "import gymnasium as gym\n",
    "\n",
    "from envs.atari import make_atari_env\n",
    "\n",
    "env_id = 'ALE/Pong-v5'\n",
    "\n",
    "env = make_atari_env(env_id, seed=0, frame_stack=4, clip_rewards=True, full_action_space=True)\n",
    "obs, info = env.reset()\n",
    "print('obs shape:', obs.shape, 'dtype:', obs.dtype)\n",
    "print('action space:', env.action_space)\n",
    "\n",
    "obs, r, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "print('step -> reward:', r, 'done:', terminated or truncated)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3fac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a small Day/Night experiment on multiple Atari games\n",
    "import torch\n",
    "\n",
    "from config import Config\n",
    "from training.day_night import DayNightTrainer\n",
    "\n",
    "GAMES = [\n",
    "    'ALE/Pong-v5',\n",
    "    'ALE/Breakout-v5',\n",
    "    'ALE/SpaceInvaders-v5',\n",
    "]\n",
    "\n",
    "cfg = Config(\n",
    "    num_experts=8,\n",
    "    games_per_day=2,\n",
    "    day_steps_per_game=1500,          # keep small for smoke test\n",
    "    sleep_updates_per_game=100,       # keep small for smoke test\n",
    "    batch_size=16,\n",
    "    seq_len=8,\n",
    "    ewc_lambda=0.2,\n",
    "    top_experts_per_game=3,\n",
    "    protect_experts=True,\n",
    "    protect_encoder=False,\n",
    ")\n",
    "\n",
    "trainer = DayNightTrainer(GAMES, cfg, seed=0)\n",
    "\n",
    "for day in range(2):\n",
    "    result = trainer.run_one_day(day)\n",
    "    print('\n",
    "=== DAY', day, '===')\n",
    "    print('games_today:', result['games_today'])\n",
    "    print('cache_hit_rate:', result['cache_hit_rate'])\n",
    "    print('flagged_experts:', result['flagged_experts'])\n",
    "    print('episode_returns (per-game):')\n",
    "    for g, rets in result['episode_returns'].items():\n",
    "        print(' ', g, 'n_eps', len(rets), 'last_return', (rets[-1] if rets else None))\n",
    "    print('sleep:', result['sleep'])\n",
    "    print('ewc_tasks:', result['ewc_tasks'])\n",
    "\n",
    "print('\n",
    "Done.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
