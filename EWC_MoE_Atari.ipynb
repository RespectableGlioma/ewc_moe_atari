{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e79f1e1",
   "metadata": {},
   "source": [
    "# Out-of-Core-ish MoE + EWC Multi-Atari: Day/Night Training (Gymnasium)\n",
    "\n",
    "This notebook runs a **biologically inspired** loop:\n",
    "\n",
    "- **Day:** play *K* Atari games sequentially (highly correlated stream). A **shared GRU router** infers context and gates a sparse set of experts.\n",
    "- **Sleep:** shuffle replay from **only those games encountered today** (more IID-like gradients), do SGD updates.\n",
    "- **Retention:** **EWC** protects (router + optionally encoder + per-game flagged experts).\n",
    "- **Out-of-core mechanism:** a real `ExpertStore` pages experts across **GPU (HBM)** ↔ **CPU (DRAM)** ↔ **disk (NVMe)**.\n",
    "\n",
    "**Important for persistence:** if you mount Google Drive, the run directory (metrics + expert shards) survives Colab restarts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd8f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install deps (Colab)\n",
    "# NOTE: We intentionally do NOT `pip install -U torch` in Colab because it can accidentally\n",
    "# downgrade/replace the preinstalled CUDA build.\n",
    "!pip -q install -U   'gymnasium[atari,accept-rom-license]'   opencv-python   pandas   matplotlib   tensorboard\n",
    "\n",
    "import gymnasium\n",
    "print('Gymnasium version:', gymnasium.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acaebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional but recommended) Mount Google Drive for persistence\n",
    "import os, time\n",
    "\n",
    "RUN_BASE = None\n",
    "\n",
    "try:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount('/content/drive')\n",
    "    if os.path.exists('/content/drive/MyDrive'):\n",
    "        RUN_BASE = '/content/drive/MyDrive/ewc_moe_atari_runs'\n",
    "except Exception as e:\n",
    "    print('Drive mount skipped / not in Colab:', e)\n",
    "\n",
    "if RUN_BASE is None:\n",
    "    # Ephemeral (will be lost if runtime resets)\n",
    "    RUN_BASE = '/content/ewc_moe_atari_runs'\n",
    "\n",
    "run_id = time.strftime('%Y%m%d_%H%M%S')\n",
    "RUN_DIR = os.path.join(RUN_BASE, run_id)\n",
    "os.makedirs(RUN_DIR, exist_ok=True)\n",
    "\n",
    "print('RUN_DIR:', RUN_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8441b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make repo imports work regardless of Colab's current working directory.\n",
    "# We locate the project root by searching for `src/envs/atari.py`.\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _find_project_root() -> Path:\n",
    "    cwd = Path.cwd().resolve()\n",
    "\n",
    "    # 1) Check cwd and parents\n",
    "    for p in [cwd, *cwd.parents]:\n",
    "        if (p / 'src' / 'envs' / 'atari.py').is_file():\n",
    "            return p\n",
    "\n",
    "    # 2) Common unzip location\n",
    "    common = Path('/content/ewc_moe_atari_colab').resolve()\n",
    "    if (common / 'src' / 'envs' / 'atari.py').is_file():\n",
    "        return common\n",
    "\n",
    "    # 3) Shallow BFS under /content (depth-limited)\n",
    "    base = Path('/content').resolve()\n",
    "    if base.exists():\n",
    "        queue = [(base, 0)]\n",
    "        while queue:\n",
    "            node, depth = queue.pop(0)\n",
    "            if (node / 'src' / 'envs' / 'atari.py').is_file():\n",
    "                return node\n",
    "            if depth < 4:\n",
    "                try:\n",
    "                    for child in node.iterdir():\n",
    "                        if child.is_dir() and child.name not in ('__pycache__', '.ipynb_checkpoints'):\n",
    "                            queue.append((child, depth + 1))\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    # Fallback\n",
    "    return cwd\n",
    "\n",
    "\n",
    "PROJECT_DIR = _find_project_root()\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "SRC_DIR = str(PROJECT_DIR / 'src')\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.insert(0, SRC_DIR)\n",
    "\n",
    "print('PROJECT_DIR:', PROJECT_DIR)\n",
    "print('SRC_DIR:', SRC_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d7ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick environment smoke test\n",
    "from envs import make_atari_env\n",
    "\n",
    "env = make_atari_env('ALE/Breakout-v5', seed=0, frame_stack=4, clip_rewards=True, full_action_space=True)\n",
    "obs, info = env.reset()\n",
    "print('obs shape:', obs.shape, 'dtype:', obs.dtype, 'action_space:', env.action_space)\n",
    "\n",
    "for _ in range(5):\n",
    "    obs, rew, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    if terminated or truncated:\n",
    "        obs, info = env.reset()\n",
    "\n",
    "env.close()\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218dbe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a small multi-day experiment\n",
    "from config import Config\n",
    "from training import DayNightTrainer\n",
    "from logging_utils import RunLogger\n",
    "\n",
    "# Pick a suite of games. (You can expand this list.)\n",
    "GAMES = [\n",
    "    'ALE/Breakout-v5',\n",
    "    'ALE/SpaceInvaders-v5',\n",
    "    'ALE/Pong-v5',\n",
    "    'ALE/Seaquest-v5',\n",
    "    'ALE/Qbert-v5',\n",
    "    'ALE/BeamRider-v5',\n",
    "]\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "# You asked for longer days (more games). Tune these up as your runtime allows.\n",
    "cfg.games_per_day = 5\n",
    "cfg.day_steps_per_game = 2500\n",
    "cfg.sleep_updates_per_game = 250\n",
    "\n",
    "# Make the expert suite bigger to force paging.\n",
    "cfg.num_experts = 64\n",
    "cfg.expert_top_k = 2\n",
    "\n",
    "# Tight budgets so we see real HBM/DRAM/NVMe behavior.\n",
    "cfg.hbm_expert_capacity = 4\n",
    "cfg.dram_expert_capacity = 12\n",
    "cfg.enable_nvme_tier = True\n",
    "\n",
    "# For faster iteration in Colab:\n",
    "cfg.batch_size = 16\n",
    "cfg.seq_len = 8\n",
    "\n",
    "print(cfg)\n",
    "\n",
    "logger = RunLogger(RUN_DIR, config=cfg)\n",
    "trainer = DayNightTrainer(GAMES, cfg, seed=0, run_dir=RUN_DIR)\n",
    "\n",
    "NUM_DAYS = 3\n",
    "\n",
    "for day in range(NUM_DAYS):\n",
    "    print(f'=== DAY {day} ===')\n",
    "    out = trainer.run_one_day(day)\n",
    "\n",
    "    # Human-readable quick summary\n",
    "    print('games_today:', out['games_today'])\n",
    "    for g in out['games_today']:\n",
    "        print(' ', g,\n",
    "              'n_eps', out['n_episodes'][g],\n",
    "              'last_return', out['episode_return_last'][g],\n",
    "              'mean_return', out['episode_return_mean'][g],\n",
    "              'hbm_hit_rate', out['day_cache'][g]['hbm_hit_rate'],\n",
    "              'nvme_reads', out['day_cache'][g]['nvme_reads'])\n",
    "\n",
    "    logger.log(day, out)\n",
    "\n",
    "logger.close()\n",
    "print('Done. Logs saved in:', RUN_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6434e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics + plot\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from viz.metrics import load_jsonl, metrics_to_frame\n",
    "\n",
    "records = load_jsonl(os.path.join(RUN_DIR, 'metrics.jsonl'))\n",
    "df = metrics_to_frame(records)\n",
    "print('df shape:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a591f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot episode return (mean) per game across days\n",
    "import numpy as np\n",
    "\n",
    "# Columns are like: episode_return_mean/ALE/Breakout-v5\n",
    "cols = [c for c in df.columns if c.startswith('episode_return_mean/')]\n",
    "\n",
    "plt.figure()\n",
    "for c in cols:\n",
    "    plt.plot(df['_step'], df[c], marker='o', label=c.replace('episode_return_mean/', ''))\n",
    "plt.xlabel('day')\n",
    "plt.ylabel('mean episode return (day)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f672d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot expert-store behavior: HBM hit rate + NVMe reads\n",
    "cache_cols = [c for c in df.columns if c.startswith('day_cache/') and c.endswith('/hbm_hit_rate')]\n",
    "read_cols = [c for c in df.columns if c.startswith('day_cache/') and c.endswith('/nvme_reads')]\n",
    "\n",
    "plt.figure()\n",
    "for c in cache_cols:\n",
    "    plt.plot(df['_step'], df[c], marker='o', label=c.replace('day_cache/', '').replace('/hbm_hit_rate',''))\n",
    "plt.xlabel('day')\n",
    "plt.ylabel('HBM hit rate (day)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for c in read_cols:\n",
    "    plt.plot(df['_step'], df[c], marker='o', label=c.replace('day_cache/', '').replace('/nvme_reads',''))\n",
    "plt.xlabel('day')\n",
    "plt.ylabel('NVMe reads (count, day)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f34d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard (optional)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {os.path.join(RUN_DIR, 'tb')}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
