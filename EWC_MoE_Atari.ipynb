{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3e79f1e1",
      "metadata": {
        "id": "3e79f1e1"
      },
      "source": [
        "# Out-of-Core-ish MoE + EWC Multi-Atari: Day/Night Training (Gymnasium)\n",
        "\n",
        "This notebook runs a **biologically inspired** loop:\n",
        "\n",
        "- **Day:** play *K* Atari games sequentially (highly correlated stream). A **shared GRU router** infers context and gates a sparse set of experts.\n",
        "- **Sleep:** shuffle replay from **only those games encountered today** (more IID-like gradients), do SGD updates.\n",
        "- **Retention:** **EWC** protects (router + optionally encoder + per-game flagged experts).\n",
        "- **Out-of-core mechanism:** a real `ExpertStore` pages experts across **GPU (HBM)** ↔ **CPU (DRAM)** ↔ **disk (NVMe)**.\n",
        "\n",
        "**Important for persistence:** if you mount Google Drive, the run directory (metrics + expert shards) survives Colab restarts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c2fd8f38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2fd8f38",
        "outputId": "5fb9b510-f026-4e2d-aeb8-f2b725829711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: gymnasium 1.2.3 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m135.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires tensorboard~=2.19.0, but you have tensorboard 2.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mGymnasium version: 1.2.3\n"
          ]
        }
      ],
      "source": [
        "# Install deps (Colab)\n",
        "# NOTE: We intentionally do NOT `pip install -U torch` in Colab because it can accidentally\n",
        "# downgrade/replace the preinstalled CUDA build.\n",
        "!pip -q install -U   'gymnasium[atari,accept-rom-license]'   opencv-python   pandas   matplotlib   tensorboard\n",
        "\n",
        "import gymnasium\n",
        "print('Gymnasium version:', gymnasium.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4acaebd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4acaebd4",
        "outputId": "96e63166-21a4-4e01-d50e-4b63fa75d8d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "RUN_DIR: /content/drive/MyDrive/ewc_moe_atari_runs/20260120_130029\n"
          ]
        }
      ],
      "source": [
        "# (Optional but recommended) Mount Google Drive for persistence\n",
        "import os, time\n",
        "\n",
        "RUN_BASE = None\n",
        "\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive')\n",
        "    if os.path.exists('/content/drive/MyDrive'):\n",
        "        RUN_BASE = '/content/drive/MyDrive/ewc_moe_atari_runs'\n",
        "except Exception as e:\n",
        "    print('Drive mount skipped / not in Colab:', e)\n",
        "\n",
        "if RUN_BASE is None:\n",
        "    # Ephemeral (will be lost if runtime resets)\n",
        "    RUN_BASE = '/content/ewc_moe_atari_runs'\n",
        "\n",
        "run_id = time.strftime('%Y%m%d_%H%M%S')\n",
        "RUN_DIR = os.path.join(RUN_BASE, run_id)\n",
        "os.makedirs(RUN_DIR, exist_ok=True)\n",
        "\n",
        "print('RUN_DIR:', RUN_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8441b3ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8441b3ec",
        "outputId": "c1b07d52-87f6-4169-9cb8-51a2917fd870"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROJECT_DIR: /content/ewc_moe_atari\n",
            "SRC_DIR: /content/ewc_moe_atari/src\n"
          ]
        }
      ],
      "source": [
        "# Make repo imports work regardless of Colab's current working directory.\n",
        "# We locate the project root by searching for `src/envs/atari.py`.\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def _find_project_root() -> Path:\n",
        "    cwd = Path.cwd().resolve()\n",
        "\n",
        "    # 1) Check cwd and parents\n",
        "    for p in [cwd, *cwd.parents]:\n",
        "        if (p / 'src' / 'envs' / 'atari.py').is_file():\n",
        "            return p\n",
        "\n",
        "    # 2) Common unzip location\n",
        "    common = Path('/content/ewc_moe_atari_colab').resolve()\n",
        "    if (common / 'src' / 'envs' / 'atari.py').is_file():\n",
        "        return common\n",
        "\n",
        "    # 3) Shallow BFS under /content (depth-limited)\n",
        "    base = Path('/content').resolve()\n",
        "    if base.exists():\n",
        "        queue = [(base, 0)]\n",
        "        while queue:\n",
        "            node, depth = queue.pop(0)\n",
        "            if (node / 'src' / 'envs' / 'atari.py').is_file():\n",
        "                return node\n",
        "            if depth < 4:\n",
        "                try:\n",
        "                    for child in node.iterdir():\n",
        "                        if child.is_dir() and child.name not in ('__pycache__', '.ipynb_checkpoints'):\n",
        "                            queue.append((child, depth + 1))\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    # Fallback\n",
        "    return cwd\n",
        "\n",
        "\n",
        "PROJECT_DIR = _find_project_root()\n",
        "os.chdir(PROJECT_DIR)\n",
        "\n",
        "SRC_DIR = str(PROJECT_DIR / 'src')\n",
        "if SRC_DIR not in sys.path:\n",
        "    sys.path.insert(0, SRC_DIR)\n",
        "\n",
        "print('PROJECT_DIR:', PROJECT_DIR)\n",
        "print('SRC_DIR:', SRC_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "397d7ef9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "397d7ef9",
        "outputId": "40918a95-b396-4bf1-bf5f-f45c305a4c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obs shape: (4, 84, 84) dtype: uint8 action_space: Discrete(18)\n",
            "ok\n"
          ]
        }
      ],
      "source": [
        "# Quick environment smoke test\n",
        "from envs import make_atari_env\n",
        "\n",
        "env = make_atari_env('ALE/Breakout-v5', seed=0, frame_stack=4, clip_rewards=True, full_action_space=True)\n",
        "obs, info = env.reset()\n",
        "print('obs shape:', obs.shape, 'dtype:', obs.dtype, 'action_space:', env.action_space)\n",
        "\n",
        "for _ in range(5):\n",
        "    obs, rew, terminated, truncated, info = env.step(env.action_space.sample())\n",
        "    if terminated or truncated:\n",
        "        obs, info = env.reset()\n",
        "\n",
        "env.close()\n",
        "print('ok')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "218dbe59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "218dbe59",
        "outputId": "f71a3601-2839-4cfa-e416-247d270dd1c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config(frame_stack=4, reward_clip=True, num_experts=256, router_hidden_dim=128, expert_hidden_dim=256, feature_dim=512, expert_top_k=2, hbm_expert_capacity=4, dram_expert_capacity=16, enable_nvme_tier=True, pin_cpu_memory=True, gamma=0.99, learning_rate=0.0001, batch_size=16, seq_len=8, epsilon_start=1.0, epsilon_end=0.1, epsilon_decay_steps=50000, target_update_interval=1000, games_per_day=8, day_steps_per_game=4000, sleep_updates_per_game=400, salience_alpha=0.6, td_error_weight=1.0, policy_surprisal_weight=0.2, softmax_temp_for_surprisal=1.0, ewc_lambda=0.4, fisher_batches=25, top_experts_per_game=4, protect_encoder=False, protect_experts=True, log_every_sleep_steps=50)\n",
            "=== DAY 0 ===\n",
            "games_today: ['ALE/Seaquest-v5', 'ALE/BeamRider-v5', 'ALE/Breakout-v5', 'ALE/SpaceInvaders-v5', 'ALE/Pong-v5', 'ALE/Qbert-v5']\n",
            "  ALE/Seaquest-v5 n_eps 6 last_return 2.0 mean_return 4.5 hbm_hit_rate 0.9998125 nvme_reads 3\n",
            "  ALE/BeamRider-v5 n_eps 2 last_return 8.0 mean_return 11.5 hbm_hit_rate 1.0 nvme_reads 0\n",
            "  ALE/Breakout-v5 n_eps 22 last_return 1.0 mean_return 1.4545454545454546 hbm_hit_rate 1.0 nvme_reads 0\n",
            "  ALE/SpaceInvaders-v5 n_eps 7 last_return 11.0 mean_return 8.428571428571429 hbm_hit_rate 1.0 nvme_reads 0\n",
            "  ALE/Pong-v5 n_eps 4 last_return -21.0 mean_return -20.75 hbm_hit_rate 1.0 nvme_reads 0\n",
            "  ALE/Qbert-v5 n_eps 13 last_return 0.0 mean_return 1.0 hbm_hit_rate 1.0 nvme_reads 0\n",
            "=== DAY 1 ===\n",
            "games_today: ['ALE/SpaceInvaders-v5', 'ALE/Qbert-v5', 'ALE/Breakout-v5', 'ALE/BeamRider-v5', 'ALE/Seaquest-v5', 'ALE/Pong-v5']\n",
            "  ALE/SpaceInvaders-v5 n_eps 6 last_return 10.0 mean_return 11.666666666666666 hbm_hit_rate 0.999875 nvme_reads 0\n",
            "  ALE/Qbert-v5 n_eps 10 last_return 5.0 mean_return 7.8 hbm_hit_rate 0.9998125 nvme_reads 0\n",
            "  ALE/Breakout-v5 n_eps 21 last_return 0.0 mean_return 1.3333333333333333 hbm_hit_rate 0.999875 nvme_reads 0\n",
            "  ALE/BeamRider-v5 n_eps 3 last_return 2.0 mean_return 4.333333333333333 hbm_hit_rate 0.999875 nvme_reads 0\n",
            "  ALE/Seaquest-v5 n_eps 2 last_return 19.0 mean_return 22.5 hbm_hit_rate 0.999875 nvme_reads 0\n",
            "  ALE/Pong-v5 n_eps 4 last_return -21.0 mean_return -20.5 hbm_hit_rate 0.999875 nvme_reads 0\n",
            "=== DAY 2 ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-893162401.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mday\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_DAYS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'=== DAY {day} ==='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_one_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Human-readable quick summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ewc_moe_atari/src/training/day_night.py\u001b[0m in \u001b[0;36mrun_one_day\u001b[0;34m(self, day_index)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflagged_experts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0msleep_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgames_today\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# Flush sleep buffer at end of sleep cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ewc_moe_atari/src/training/day_night.py\u001b[0m in \u001b[0;36mrun_sleep\u001b[0;34m(self, games_today)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpert_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mused_experts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                     \u001b[0;31m# Clip grads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "# Run a small multi-day experiment\n",
        "from config import Config\n",
        "from training import DayNightTrainer\n",
        "from logging_utils import RunLogger\n",
        "\n",
        "# Pick a suite of games. (You can expand this list.)\n",
        "GAMES = [\n",
        "    'ALE/Breakout-v5',\n",
        "    'ALE/SpaceInvaders-v5',\n",
        "    'ALE/Pong-v5',\n",
        "    'ALE/Seaquest-v5',\n",
        "    'ALE/Qbert-v5',\n",
        "    'ALE/BeamRider-v5',\n",
        "]\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# You asked for longer days (more games). Tune these up as your runtime allows.\n",
        "cfg.games_per_day = 8           # longer days\n",
        "cfg.day_steps_per_game = 4000\n",
        "cfg.sleep_updates_per_game = 400\n",
        "\n",
        "# Make the expert suite bigger to force paging.\n",
        "cfg.num_experts = 256           # make it “big enough” to matter\n",
        "cfg.expert_top_k = 2\n",
        "\n",
        "# Tight budgets so we see real HBM/DRAM/NVMe behavior.\n",
        "cfg.hbm_expert_capacity = 4     # force HBM pressure\n",
        "cfg.dram_expert_capacity = 16   # force DRAM pressure\n",
        "cfg.enable_nvme_tier = True     # enable disk tier\n",
        "\n",
        "\n",
        "# For faster iteration in Colab:\n",
        "cfg.batch_size = 16\n",
        "cfg.seq_len = 8\n",
        "\n",
        "print(cfg)\n",
        "\n",
        "logger = RunLogger(RUN_DIR, config=cfg)\n",
        "trainer = DayNightTrainer(GAMES, cfg, seed=0, run_dir=RUN_DIR)\n",
        "\n",
        "NUM_DAYS = 3\n",
        "\n",
        "for day in range(NUM_DAYS):\n",
        "    print(f'=== DAY {day} ===')\n",
        "    out = trainer.run_one_day(day)\n",
        "\n",
        "    # Human-readable quick summary\n",
        "    print('games_today:', out['games_today'])\n",
        "    for g in out['games_today']:\n",
        "        print(' ', g,\n",
        "              'n_eps', out['n_episodes'][g],\n",
        "              'last_return', out['episode_return_last'][g],\n",
        "              'mean_return', out['episode_return_mean'][g],\n",
        "              'hbm_hit_rate', out['day_cache'][g]['hbm_hit_rate'],\n",
        "              'nvme_reads', out['day_cache'][g]['nvme_reads'])\n",
        "\n",
        "    logger.log(day, out)\n",
        "\n",
        "logger.close()\n",
        "print('Done. Logs saved in:', RUN_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tVdhDADzb6ZA"
      },
      "id": "tVdhDADzb6ZA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Cy-dLCJC92i"
      },
      "id": "5Cy-dLCJC92i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a6434e3",
      "metadata": {
        "id": "5a6434e3"
      },
      "outputs": [],
      "source": [
        "# Load metrics + plot\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from viz.metrics import load_jsonl, metrics_to_frame\n",
        "\n",
        "records = load_jsonl(os.path.join(RUN_DIR, 'metrics.jsonl'))\n",
        "df = metrics_to_frame(records)\n",
        "print('df shape:', df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69a591f0",
      "metadata": {
        "id": "69a591f0"
      },
      "outputs": [],
      "source": [
        "# Plot episode return (mean) per game across days\n",
        "import numpy as np\n",
        "\n",
        "# Columns are like: episode_return_mean/ALE/Breakout-v5\n",
        "cols = [c for c in df.columns if c.startswith('episode_return_mean/')]\n",
        "\n",
        "plt.figure()\n",
        "for c in cols:\n",
        "    plt.plot(df['_step'], df[c], marker='o', label=c.replace('episode_return_mean/', ''))\n",
        "plt.xlabel('day')\n",
        "plt.ylabel('mean episode return (day)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oMo9cr0CIVl7"
      },
      "id": "oMo9cr0CIVl7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f672d3f",
      "metadata": {
        "id": "1f672d3f"
      },
      "outputs": [],
      "source": [
        "# Plot expert-store behavior: HBM hit rate + NVMe reads\n",
        "cache_cols = [c for c in df.columns if c.startswith('day_cache/') and c.endswith('/hbm_hit_rate')]\n",
        "read_cols = [c for c in df.columns if c.startswith('day_cache/') and c.endswith('/nvme_reads')]\n",
        "\n",
        "plt.figure()\n",
        "for c in cache_cols:\n",
        "    plt.plot(df['_step'], df[c], marker='o', label=c.replace('day_cache/', '').replace('/hbm_hit_rate',''))\n",
        "plt.xlabel('day')\n",
        "plt.ylabel('HBM hit rate (day)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "for c in read_cols:\n",
        "    plt.plot(df['_step'], df[c], marker='o', label=c.replace('day_cache/', '').replace('/nvme_reads',''))\n",
        "plt.xlabel('day')\n",
        "plt.ylabel('NVMe reads (count, day)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b7f34d6",
      "metadata": {
        "id": "3b7f34d6"
      },
      "outputs": [],
      "source": [
        "# TensorBoard (optional)\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {os.path.join(RUN_DIR, 'tb')}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# after creating trainer\n",
        "print(\"device:\", trainer.device)\n",
        "print(\"model expert[0] device:\", next(trainer.model.experts[0].parameters()).device)\n",
        "trainer.expert_store.reset_stats()\n",
        "\n",
        "# force a forward\n",
        "g = \"ALE/Breakout-v5\"\n",
        "env = make_atari_env(g, seed=0, frame_stack=cfg.frame_stack, clip_rewards=True, full_action_space=True)\n",
        "obs, _ = env.reset()\n",
        "h = trainer.model.init_hidden(1, trainer.device)\n",
        "obs_t = torch.from_numpy(obs).unsqueeze(0).to(trainer.device)\n",
        "_ = trainer.model(obs_t, h, expert_store=trainer.expert_store, top_k=cfg.expert_top_k)\n",
        "\n",
        "s = trainer.expert_store.reset_stats()\n",
        "print(\"hbm_hits:\", s.hbm_hits, \"hbm_misses:\", s.hbm_misses, \"hit_rate:\", s.hit_rate())\n",
        "env.close()\n"
      ],
      "metadata": {
        "id": "k3vx8Rtg-YG9"
      },
      "id": "k3vx8Rtg-YG9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2wm2SjZIpIJ"
      },
      "id": "F2wm2SjZIpIJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}