{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Out-of-Core MOE for Multi-Task RL\n",
        "\n",
        "This notebook implements a **Mixture of Experts** architecture with **tiered memory hierarchy** for sequential multi-task Atari learning.\n",
        "\n",
        "## Core Hypothesis\n",
        "\n",
        "Sequential training causes catastrophic forgetting. But with MOE + environment-aware routing:\n",
        "\n",
        "1. Different games activate different experts - natural task separation\n",
        "2. Game identity is temporally correlated - perfect for caching\n",
        "3. Sequential presentation becomes a feature - cold experts stay protected"
      ],
      "metadata": {"id": "header"}
    },
    {
      "cell_type": "markdown",
      "source": ["## 1. Setup"],
      "metadata": {"id": "setup_header"}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch numpy\n",
        "!pip install -q gymnasium opencv-python matplotlib"
      ],
      "metadata": {"id": "install"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'CUDA: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
      ],
      "metadata": {"id": "check_gpu"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('ooc_moe/core', exist_ok=True)\n",
        "os.makedirs('ooc_moe/models', exist_ok=True)\n",
        "os.makedirs('ooc_moe/envs', exist_ok=True)\n",
        "for f in ['', '/core', '/models', '/envs']:\n",
        "    open(f'ooc_moe{f}/__init__.py', 'w').close()\n",
        "print('Project structure created')"
      ],
      "metadata": {"id": "create_dirs"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## 2. Core Components"],
      "metadata": {"id": "core_header"}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ooc_moe/core/tiered_store.py\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from typing import Dict, List, Optional, Tuple, Set\n",
        "from collections import OrderedDict\n",
        "from dataclasses import dataclass, field\n",
        "from threading import Lock, Thread\n",
        "from queue import Queue, Empty\n",
        "import time\n",
        "from enum import Enum\n",
        "\n",
        "class StorageTier(Enum):\n",
        "    HBM = 'hbm'\n",
        "    DRAM = 'dram'\n",
        "    NVME = 'nvme'\n",
        "\n",
        "@dataclass\n",
        "class CacheStats:\n",
        "    hits: int = 0\n",
        "    misses: int = 0\n",
        "    prefetch_hits: int = 0\n",
        "    evictions: int = 0\n",
        "    tier_accesses: Dict[StorageTier, int] = field(default_factory=dict)\n",
        "    \n",
        "    @property\n",
        "    def hit_rate(self) -> float:\n",
        "        total = self.hits + self.misses\n",
        "        return self.hits / total if total > 0 else 0.0\n",
        "\n",
        "class LRUCache:\n",
        "    def __init__(self, capacity: int):\n",
        "        self.capacity = capacity\n",
        "        self.cache = OrderedDict()\n",
        "        self.lock = Lock()\n",
        "        self.prefetched = set()\n",
        "    \n",
        "    def get(self, key: int):\n",
        "        with self.lock:\n",
        "            if key not in self.cache:\n",
        "                return None\n",
        "            self.cache.move_to_end(key)\n",
        "            was_pf = key in self.prefetched\n",
        "            self.prefetched.discard(key)\n",
        "            return self.cache[key], was_pf\n",
        "    \n",
        "    def put(self, key: int, value, is_prefetch: bool = False):\n",
        "        with self.lock:\n",
        "            evicted = None\n",
        "            if key in self.cache:\n",
        "                self.cache.move_to_end(key)\n",
        "                self.cache[key] = value\n",
        "            else:\n",
        "                if len(self.cache) >= self.capacity:\n",
        "                    evicted, _ = self.cache.popitem(last=False)\n",
        "                    self.prefetched.discard(evicted)\n",
        "                self.cache[key] = value\n",
        "            if is_prefetch:\n",
        "                self.prefetched.add(key)\n",
        "            return evicted\n",
        "    \n",
        "    def __contains__(self, key):\n",
        "        with self.lock:\n",
        "            return key in self.cache\n",
        "    \n",
        "    def __len__(self):\n",
        "        with self.lock:\n",
        "            return len(self.cache)\n",
        "\n",
        "class TieredExpertStore:\n",
        "    def __init__(self, num_experts, expert_dim, hidden_dim, hbm_capacity=32,\n",
        "                 dram_capacity=128, device='cuda', simulate_latency=True):\n",
        "        self.num_experts = num_experts\n",
        "        self.expert_dim = expert_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.device = device\n",
        "        self.simulate_latency = simulate_latency\n",
        "        self.hbm_capacity = hbm_capacity\n",
        "        self.dram_capacity = dram_capacity\n",
        "        \n",
        "        self.hbm_cache = LRUCache(hbm_capacity)\n",
        "        self.dram_cache = LRUCache(dram_capacity)\n",
        "        self.nvme_store = {}\n",
        "        self._init_experts()\n",
        "        \n",
        "        self.prefetch_queue = Queue()\n",
        "        self.stop_prefetch = False\n",
        "        self.stats = CacheStats()\n",
        "        self.stats.tier_accesses = {t: 0 for t in StorageTier}\n",
        "        \n",
        "        self.prefetch_worker = Thread(target=self._prefetch_loop, daemon=True)\n",
        "        self.prefetch_worker.start()\n",
        "    \n",
        "    def _init_experts(self):\n",
        "        for i in range(self.num_experts):\n",
        "            self.nvme_store[i] = {\n",
        "                'w1': torch.randn(self.hidden_dim, self.expert_dim) * 0.02,\n",
        "                'w2': torch.randn(self.expert_dim, self.hidden_dim) * 0.02,\n",
        "                'b1': torch.zeros(self.hidden_dim),\n",
        "                'b2': torch.zeros(self.expert_dim),\n",
        "            }\n",
        "    \n",
        "    def _prefetch_loop(self):\n",
        "        while not self.stop_prefetch:\n",
        "            try:\n",
        "                eid = self.prefetch_queue.get(timeout=0.1)\n",
        "                self._promote(eid, is_prefetch=True)\n",
        "            except Empty:\n",
        "                continue\n",
        "    \n",
        "    def _promote(self, expert_id, is_prefetch=False):\n",
        "        result = self.hbm_cache.get(expert_id)\n",
        "        if result:\n",
        "            params, was_pf = result\n",
        "            self.stats.hits += 1\n",
        "            if was_pf:\n",
        "                self.stats.prefetch_hits += 1\n",
        "            self.stats.tier_accesses[StorageTier.HBM] += 1\n",
        "            return params\n",
        "        \n",
        "        result = self.dram_cache.get(expert_id)\n",
        "        if result:\n",
        "            params_cpu, was_pf = result\n",
        "            if self.simulate_latency:\n",
        "                time.sleep(0.001)\n",
        "            params_gpu = {k: v.to(self.device) for k, v in params_cpu.items()}\n",
        "            self.hbm_cache.put(expert_id, params_gpu, is_prefetch)\n",
        "            self.stats.hits += 1\n",
        "            self.stats.tier_accesses[StorageTier.DRAM] += 1\n",
        "            return params_gpu\n",
        "        \n",
        "        if self.simulate_latency:\n",
        "            time.sleep(0.01)\n",
        "        params_cold = self.nvme_store[expert_id]\n",
        "        params_gpu = {k: v.to(self.device) for k, v in params_cold.items()}\n",
        "        evicted = self.hbm_cache.put(expert_id, params_gpu, is_prefetch)\n",
        "        if evicted is not None:\n",
        "            self.stats.evictions += 1\n",
        "        self.stats.misses += 1\n",
        "        self.stats.tier_accesses[StorageTier.NVME] += 1\n",
        "        return params_gpu\n",
        "    \n",
        "    def get_experts(self, expert_ids, context_hash=None):\n",
        "        return {eid: self._promote(eid) for eid in expert_ids}\n",
        "    \n",
        "    def prefetch(self, expert_ids):\n",
        "        for eid in expert_ids:\n",
        "            if eid not in self.hbm_cache:\n",
        "                self.prefetch_queue.put(eid)\n",
        "    \n",
        "    def get_stats_summary(self):\n",
        "        return {\n",
        "            'hit_rate': self.stats.hit_rate,\n",
        "            'total_hits': self.stats.hits,\n",
        "            'total_misses': self.stats.misses,\n",
        "            'prefetch_hits': self.stats.prefetch_hits,\n",
        "            'evictions': self.stats.evictions,\n",
        "            'hbm_occupancy': len(self.hbm_cache) / self.hbm_capacity,\n",
        "        }\n",
        "    \n",
        "    def shutdown(self):\n",
        "        self.stop_prefetch = True\n",
        "        self.prefetch_worker.join(timeout=2.0)"
      ],
      "metadata": {"id": "tiered_store"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ooc_moe/core/moe_layers.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from typing import Dict, List, Optional, Tuple, NamedTuple\n",
        "from .tiered_store import TieredExpertStore\n",
        "\n",
        "class RouterOutput(NamedTuple):\n",
        "    expert_indices: Tensor\n",
        "    expert_weights: Tensor\n",
        "    router_logits: Tensor\n",
        "    load_balancing_loss: Tensor\n",
        "\n",
        "class ExpertRouter(nn.Module):\n",
        "    def __init__(self, input_dim, num_experts, top_k=2, noise_std=0.1):\n",
        "        super().__init__()\n",
        "        self.num_experts = num_experts\n",
        "        self.top_k = top_k\n",
        "        self.noise_std = noise_std\n",
        "        self.router = nn.Linear(input_dim, num_experts, bias=False)\n",
        "        nn.init.normal_(self.router.weight, std=0.01)\n",
        "    \n",
        "    def forward(self, x, training=True):\n",
        "        batch_size = x.shape[0]\n",
        "        logits = self.router(x)\n",
        "        if training and self.noise_std > 0:\n",
        "            logits = logits + torch.randn_like(logits) * self.noise_std\n",
        "        top_k_logits, top_k_idx = torch.topk(logits, self.top_k, dim=-1)\n",
        "        weights = F.softmax(top_k_logits, dim=-1)\n",
        "        \n",
        "        mask = F.one_hot(top_k_idx, self.num_experts).float().sum(dim=1)\n",
        "        frac = mask.sum(dim=0) / batch_size\n",
        "        probs = F.softmax(logits, dim=-1).mean(dim=0)\n",
        "        lb_loss = self.num_experts * (frac * probs).sum()\n",
        "        return RouterOutput(top_k_idx, weights, logits, lb_loss)\n",
        "\n",
        "class TieredMoELayer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, expert_store, top_k=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.expert_store = expert_store\n",
        "        self.top_k = top_k\n",
        "        self.router = ExpertRouter(input_dim, expert_store.num_experts, top_k)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(input_dim)\n",
        "        self.last_expert_indices = None\n",
        "    \n",
        "    def forward(self, x, context_hash=None):\n",
        "        shape = x.shape\n",
        "        if len(shape) == 3:\n",
        "            b, s, d = shape\n",
        "            x = x.reshape(b * s, d)\n",
        "        else:\n",
        "            s = None\n",
        "        \n",
        "        x_norm = self.layer_norm(x)\n",
        "        rout = self.router(x_norm, self.training)\n",
        "        self.last_expert_indices = rout.expert_indices\n",
        "        \n",
        "        unique = rout.expert_indices.unique().tolist()\n",
        "        params = self.expert_store.get_experts(unique, context_hash)\n",
        "        \n",
        "        output = torch.zeros_like(x_norm)\n",
        "        for k in range(self.top_k):\n",
        "            idx = rout.expert_indices[:, k]\n",
        "            w = rout.expert_weights[:, k]\n",
        "            for eid in idx.unique().tolist():\n",
        "                mask = (idx == eid)\n",
        "                if not mask.any():\n",
        "                    continue\n",
        "                p = params[eid]\n",
        "                h = F.relu(x_norm[mask] @ p['w1'].T + p['b1'])\n",
        "                y = h @ p['w2'].T + p['b2']\n",
        "                output[mask] += w[mask].unsqueeze(-1) * y\n",
        "        \n",
        "        output = x + self.dropout(output)\n",
        "        if s is not None:\n",
        "            output = output.reshape(b, s, d)\n",
        "        return output, rout.load_balancing_loss\n",
        "    \n",
        "    def get_routing_stats(self):\n",
        "        if self.last_expert_indices is None:\n",
        "            return {}\n",
        "        idx = self.last_expert_indices.flatten()\n",
        "        u, c = torch.unique(idx, return_counts=True)\n",
        "        return {'num_unique_experts': len(u), 'expert_usage': {int(e): int(n) for e, n in zip(u, c)}}\n",
        "\n",
        "class MoETransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, expert_store, ffn_hidden_dim, top_k=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.attn_norm = nn.LayerNorm(dim)\n",
        "        self.attn_drop = nn.Dropout(dropout)\n",
        "        self.moe = TieredMoELayer(dim, ffn_hidden_dim, expert_store, top_k, dropout)\n",
        "    \n",
        "    def forward(self, x, attention_mask=None, context_hash=None):\n",
        "        h = self.attn_norm(x)\n",
        "        a, _ = self.attn(h, h, h, attn_mask=attention_mask, need_weights=False)\n",
        "        x = x + self.attn_drop(a)\n",
        "        x, aux = self.moe(x, context_hash)\n",
        "        return x, aux\n",
        "    \n",
        "    def get_last_routing_stats(self):\n",
        "        return self.moe.get_routing_stats()"
      ],
      "metadata": {"id": "moe_layers"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ooc_moe/core/env_detector.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import List, Tuple, NamedTuple\n",
        "\n",
        "class PredictionOutput(NamedTuple):\n",
        "    env_logits: torch.Tensor\n",
        "    expert_probs: torch.Tensor\n",
        "    prefetch_set: List[int]\n",
        "    predicted_env: int\n",
        "    confidence: float\n",
        "\n",
        "class EnvironmentDetector(nn.Module):\n",
        "    def __init__(self, obs_shape, num_envs, num_experts, hidden_dim=256, history_len=4):\n",
        "        super().__init__()\n",
        "        c, h, w = obs_shape\n",
        "        self.num_experts = num_experts\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(c * history_len, 32, 8, stride=4), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, stride=1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        with torch.no_grad():\n",
        "            out_size = self.encoder(torch.zeros(1, c * history_len, h, w)).shape[1]\n",
        "        self.proj = nn.Sequential(nn.Linear(out_size, hidden_dim), nn.ReLU())\n",
        "        self.env_head = nn.Linear(hidden_dim, num_envs)\n",
        "        self.expert_head = nn.Linear(hidden_dim, num_experts)\n",
        "    \n",
        "    def forward(self, obs):\n",
        "        h = self.proj(self.encoder(obs))\n",
        "        return self.env_head(h), torch.sigmoid(self.expert_head(h))\n",
        "    \n",
        "    @torch.no_grad()\n",
        "    def predict(self, obs, top_k=32):\n",
        "        self.eval()\n",
        "        env_logits, expert_probs = self.forward(obs)\n",
        "        env_probs = F.softmax(env_logits, dim=-1)\n",
        "        pred_env = env_probs.argmax(dim=-1).item()\n",
        "        conf = env_probs.max(dim=-1).values.item()\n",
        "        probs = expert_probs.squeeze(0)\n",
        "        prefetch = probs.topk(min(top_k, len(probs))).indices.tolist()\n",
        "        return PredictionOutput(env_logits, expert_probs, prefetch, pred_env, conf)\n",
        "    \n",
        "    def get_prefetch_set(self, obs, top_k=32):\n",
        "        return self.predict(obs, top_k).prefetch_set"
      ],
      "metadata": {"id": "env_detector"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ooc_moe/models/moe_agent.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import Dict, List, Optional, Tuple, NamedTuple\n",
        "import math\n",
        "from ..core.tiered_store import TieredExpertStore\n",
        "from ..core.moe_layers import MoETransformerBlock\n",
        "from ..core.env_detector import EnvironmentDetector\n",
        "\n",
        "class AgentOutput(NamedTuple):\n",
        "    action_logits: torch.Tensor\n",
        "    value: torch.Tensor\n",
        "    expert_ids: List[int]\n",
        "    aux_loss: torch.Tensor\n",
        "    env_prediction: int\n",
        "    cache_stats: Dict\n",
        "\n",
        "class ObsEncoder(nn.Module):\n",
        "    def __init__(self, obs_shape, out_dim=512, frame_stack=4):\n",
        "        super().__init__()\n",
        "        c, h, w = obs_shape\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(c * frame_stack, 32, 8, stride=4), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, stride=1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        with torch.no_grad():\n",
        "            conv_out = self.conv(torch.zeros(1, c * frame_stack, h, w)).shape[1]\n",
        "        self.proj = nn.Sequential(nn.Linear(conv_out, out_dim), nn.ReLU(), nn.Linear(out_dim, out_dim))\n",
        "    \n",
        "    def forward(self, obs):\n",
        "        return self.proj(self.conv(obs))\n",
        "\n",
        "class PosEncoding(nn.Module):\n",
        "    def __init__(self, dim, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, dim)\n",
        "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div = torch.exp(torch.arange(0, dim, 2).float() * (-math.log(10000.0) / dim))\n",
        "        pe[:, 0::2] = torch.sin(pos * div)\n",
        "        pe[:, 1::2] = torch.cos(pos * div)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class MoERLAgent(nn.Module):\n",
        "    def __init__(self, obs_shape, num_actions, num_experts, expert_dim=512, expert_hidden=2048,\n",
        "                 num_layers=6, num_heads=8, top_k=2, context_len=32, frame_stack=4, num_envs=57,\n",
        "                 hbm_cap=32, dram_cap=128, dropout=0.1, device='cuda'):\n",
        "        super().__init__()\n",
        "        self.context_len = context_len\n",
        "        self.device = device\n",
        "        \n",
        "        self.expert_store = TieredExpertStore(\n",
        "            num_experts, expert_dim, expert_hidden, hbm_cap, dram_cap, device, True)\n",
        "        self.obs_enc = ObsEncoder(obs_shape, expert_dim, frame_stack)\n",
        "        self.pos_enc = PosEncoding(expert_dim, context_len)\n",
        "        \n",
        "        self.blocks = nn.ModuleList([\n",
        "            MoETransformerBlock(expert_dim, num_heads, self.expert_store, expert_hidden, top_k, dropout)\n",
        "            for _ in range(num_layers)])\n",
        "        \n",
        "        self.action_head = nn.Sequential(nn.Linear(expert_dim, expert_dim), nn.ReLU(), nn.Linear(expert_dim, num_actions))\n",
        "        self.value_head = nn.Sequential(nn.Linear(expert_dim, expert_dim), nn.ReLU(), nn.Linear(expert_dim, 1))\n",
        "        self.env_detector = EnvironmentDetector(obs_shape, num_envs, num_experts, 256, frame_stack)\n",
        "        self.experts_used = []\n",
        "    \n",
        "    def forward(self, obs, env_id=None, prefetch=True):\n",
        "        b, s = obs.shape[:2]\n",
        "        device = obs.device\n",
        "        \n",
        "        env_pred = -1\n",
        "        if prefetch:\n",
        "            pred = self.env_detector.predict(obs[:, -1], top_k=32)\n",
        "            env_pred = pred.predicted_env\n",
        "            self.expert_store.prefetch(pred.prefetch_set)\n",
        "        \n",
        "        x = self.obs_enc(obs.reshape(b * s, *obs.shape[2:])).reshape(b, s, -1)\n",
        "        x = self.pos_enc(x)\n",
        "        \n",
        "        mask = torch.triu(torch.ones(s, s, device=device) * float('-inf'), diagonal=1)\n",
        "        \n",
        "        total_aux = 0.0\n",
        "        self.experts_used = []\n",
        "        for block in self.blocks:\n",
        "            x, aux = block(x, attention_mask=mask)\n",
        "            total_aux = total_aux + aux\n",
        "            stats = block.get_last_routing_stats()\n",
        "            if 'expert_usage' in stats:\n",
        "                self.experts_used.extend(stats['expert_usage'].keys())\n",
        "        \n",
        "        final = x[:, -1]\n",
        "        return AgentOutput(\n",
        "            self.action_head(final), self.value_head(final),\n",
        "            list(set(self.experts_used)), total_aux, env_pred,\n",
        "            self.expert_store.get_stats_summary())\n",
        "    \n",
        "    @torch.no_grad()\n",
        "    def get_action(self, obs, deterministic=False):\n",
        "        self.eval()\n",
        "        out = self.forward(obs, prefetch=True)\n",
        "        if deterministic:\n",
        "            action = out.action_logits.argmax(dim=-1).item()\n",
        "        else:\n",
        "            probs = F.softmax(out.action_logits, dim=-1)\n",
        "            action = torch.multinomial(probs, 1).item()\n",
        "        return action, out.value.item()\n",
        "\n",
        "class MoERLAgentConfig:\n",
        "    def __init__(self, obs_shape=(1,84,84), num_actions=18, num_envs=57, frame_stack=4,\n",
        "                 num_experts=256, expert_dim=512, expert_hidden=2048, num_layers=6,\n",
        "                 num_heads=8, top_k=2, context_len=32, dropout=0.1, hbm_cap=32, dram_cap=128):\n",
        "        self.obs_shape = obs_shape\n",
        "        self.num_actions = num_actions\n",
        "        self.num_envs = num_envs\n",
        "        self.frame_stack = frame_stack\n",
        "        self.num_experts = num_experts\n",
        "        self.expert_dim = expert_dim\n",
        "        self.expert_hidden = expert_hidden\n",
        "        self.num_layers = num_layers\n",
        "        self.num_heads = num_heads\n",
        "        self.top_k = top_k\n",
        "        self.context_len = context_len\n",
        "        self.dropout = dropout\n",
        "        self.hbm_cap = hbm_cap\n",
        "        self.dram_cap = dram_cap\n",
        "    \n",
        "    def create_agent(self, device='cuda'):\n",
        "        return MoERLAgent(\n",
        "            self.obs_shape, self.num_actions, self.num_experts, self.expert_dim,\n",
        "            self.expert_hidden, self.num_layers, self.num_heads, self.top_k,\n",
        "            self.context_len, self.frame_stack, self.num_envs, self.hbm_cap,\n",
        "            self.dram_cap, self.dropout, device)\n",
        "    \n",
        "    def estimate_params(self):\n",
        "        exp = self.num_experts * (self.expert_dim * self.expert_hidden * 2 + self.expert_hidden + self.expert_dim)\n",
        "        attn = self.num_layers * (4 * self.expert_dim * self.expert_dim)\n",
        "        return {'expert_params': exp, 'attention_params': attn, 'total': exp + attn}"
      ],
      "metadata": {"id": "moe_agent"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ooc_moe/envs/atari_wrappers.py\n",
        "import numpy as np\n",
        "from typing import Tuple, Optional, Dict\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "class DummyAtariEnv(gym.Env):\n",
        "    def __init__(self, game_id=0, obs_shape=(4, 84, 84), num_actions=18):\n",
        "        super().__init__()\n",
        "        self.game_id = game_id\n",
        "        self.obs_shape = obs_shape\n",
        "        self.num_actions = num_actions\n",
        "        self.observation_space = spaces.Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
        "        self.action_space = spaces.Discrete(num_actions)\n",
        "        self._rng = np.random.RandomState(game_id)\n",
        "        self._step = 0\n",
        "        self._pattern = self._make_pattern()\n",
        "    \n",
        "    def _make_pattern(self):\n",
        "        p = np.zeros((84, 84), dtype=np.float32)\n",
        "        for i in range(5):\n",
        "            x, y = (self.game_id * 17 + i * 13) % 84, (self.game_id * 23 + i * 7) % 84\n",
        "            s = 5 + (self.game_id % 10)\n",
        "            p[max(0,y-s):min(84,y+s), max(0,x-s):min(84,x+s)] = 128\n",
        "        return p\n",
        "    \n",
        "    def reset(self, seed=None, **kw):\n",
        "        if seed:\n",
        "            self._rng = np.random.RandomState(seed)\n",
        "        self._step = 0\n",
        "        return self._obs(), {'game_id': self.game_id}\n",
        "    \n",
        "    def step(self, action):\n",
        "        self._step += 1\n",
        "        r = 1.0 if action == self.game_id % self.num_actions else self._rng.random() * 0.1\n",
        "        done = self._step >= 1000 or self._rng.random() < 0.001\n",
        "        return self._obs(), r, done, False, {'game_id': self.game_id}\n",
        "    \n",
        "    def _obs(self):\n",
        "        base = np.clip(self._pattern + self._rng.randn(84, 84) * 20, 0, 255).astype(np.uint8)\n",
        "        return np.stack([np.clip(base + (self._step + i) % 50, 0, 255).astype(np.uint8) for i in range(self.obs_shape[0])])\n",
        "\n",
        "def create_dummy_envs(n=10):\n",
        "    return [DummyAtariEnv(i) for i in range(n)], [f'Game_{i}' for i in range(n)]"
      ],
      "metadata": {"id": "envs"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## 3. Test Components"],
      "metadata": {"id": "test_header"}
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "from ooc_moe.core.tiered_store import TieredExpertStore\n",
        "from ooc_moe.core.moe_layers import TieredMoELayer\n",
        "from ooc_moe.core.env_detector import EnvironmentDetector\n",
        "from ooc_moe.models.moe_agent import MoERLAgent, MoERLAgentConfig\n",
        "from ooc_moe.envs.atari_wrappers import DummyAtariEnv, create_dummy_envs\n",
        "\n",
        "print('All modules imported!')"
      ],
      "metadata": {"id": "imports"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Test tiered store\n",
        "store = TieredExpertStore(64, 128, 256, 8, 16, device, simulate_latency=False)\n",
        "experts = store.get_experts([0, 1, 2])\n",
        "print(f'Got {len(experts)} experts')\n",
        "print(f'Stats: {store.get_stats_summary()}')\n",
        "store.shutdown()\n",
        "print('TieredExpertStore OK')"
      ],
      "metadata": {"id": "test_store"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test full agent\n",
        "config = MoERLAgentConfig(\n",
        "    obs_shape=(1, 84, 84), num_actions=18, num_envs=5, frame_stack=4,\n",
        "    num_experts=32, expert_dim=128, expert_hidden=256, num_layers=2,\n",
        "    num_heads=4, top_k=2, context_len=4, hbm_cap=8, dram_cap=16)\n",
        "\n",
        "print('Params:', config.estimate_params())\n",
        "\n",
        "agent = config.create_agent(device)\n",
        "obs = torch.randn(1, config.context_len, config.frame_stack, 84, 84, device=device)\n",
        "out = agent(obs, env_id=0, prefetch=True)\n",
        "\n",
        "print(f'Action logits: {out.action_logits.shape}')\n",
        "print(f'Value: {out.value.shape}')\n",
        "print(f'Experts used: {len(out.expert_ids)}')\n",
        "print(f'Cache hit rate: {out.cache_stats[\"hit_rate\"]:.2%}')\n",
        "\n",
        "action, value = agent.get_action(obs)\n",
        "print(f'Action: {action}, Value: {value:.4f}')\n",
        "\n",
        "agent.expert_store.shutdown()\n",
        "print('Agent OK!')"
      ],
      "metadata": {"id": "test_agent"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## 4. Training Demo"],
      "metadata": {"id": "train_header"}
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, deque\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "config = MoERLAgentConfig(\n",
        "    obs_shape=(1, 84, 84), num_actions=18, num_envs=3, frame_stack=4,\n",
        "    num_experts=64, expert_dim=128, expert_hidden=256, num_layers=2,\n",
        "    num_heads=4, top_k=2, context_len=8, hbm_cap=16, dram_cap=32)\n",
        "\n",
        "agent = config.create_agent(device)\n",
        "envs, names = create_dummy_envs(3)\n",
        "optimizer = torch.optim.Adam(agent.parameters(), lr=1e-4)\n",
        "\n",
        "expert_usage = defaultdict(lambda: defaultdict(int))\n",
        "cache_history = []\n",
        "steps_per_game = 300\n",
        "\n",
        "for gid, (env, name) in enumerate(zip(envs, names)):\n",
        "    print(f'Training on {name}...')\n",
        "    obs, _ = env.reset()\n",
        "    buf = deque([torch.from_numpy(obs.astype(np.float32) / 255.0) for _ in range(config.context_len)], maxlen=config.context_len)\n",
        "    \n",
        "    for step in range(steps_per_game):\n",
        "        ctx = torch.stack(list(buf), dim=0).unsqueeze(0).to(device)\n",
        "        agent.train()\n",
        "        out = agent(ctx, env_id=gid, prefetch=True)\n",
        "        \n",
        "        for eid in out.expert_ids:\n",
        "            expert_usage[gid][eid] += 1\n",
        "        cache_history.append(out.cache_stats['hit_rate'])\n",
        "        \n",
        "        probs = F.softmax(out.action_logits, dim=-1)\n",
        "        action = torch.multinomial(probs, 1).item()\n",
        "        \n",
        "        next_obs, reward, done, _, _ = env.step(action)\n",
        "        \n",
        "        loss = -torch.log(probs[0, action]) * reward + 0.01 * out.aux_loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        buf.append(torch.from_numpy(next_obs.astype(np.float32) / 255.0))\n",
        "        if done:\n",
        "            obs, _ = env.reset()\n",
        "            buf = deque([torch.from_numpy(obs.astype(np.float32) / 255.0) for _ in range(config.context_len)], maxlen=config.context_len)\n",
        "    \n",
        "    print(f'  Cache hit rate: {np.mean(cache_history[-steps_per_game:]):.2%}')\n",
        "\n",
        "agent.expert_store.shutdown()\n",
        "print('Done!')"
      ],
      "metadata": {"id": "training"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "axes[0].plot(cache_history)\n",
        "axes[0].axhline(np.mean(cache_history), color='r', linestyle='--', label=f'Mean: {np.mean(cache_history):.2%}')\n",
        "axes[0].set_xlabel('Step')\n",
        "axes[0].set_ylabel('Cache Hit Rate')\n",
        "axes[0].set_title('Cache Performance')\n",
        "axes[0].legend()\n",
        "\n",
        "for gid in range(3):\n",
        "    usage = expert_usage[gid]\n",
        "    experts = list(usage.keys())[:15]\n",
        "    counts = [usage[e] for e in experts]\n",
        "    axes[1].bar([e + gid * 0.25 for e in range(len(experts))], counts, width=0.25, label=f'Game {gid}', alpha=0.7)\n",
        "\n",
        "axes[1].set_xlabel('Expert (top 15)')\n",
        "axes[1].set_ylabel('Usage Count')\n",
        "axes[1].set_title('Expert Specialization')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {"id": "visualize"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expert overlap analysis\n",
        "print('Expert Overlap Analysis')\n",
        "print('=' * 40)\n",
        "\n",
        "for gid in range(3):\n",
        "    usage = expert_usage[gid]\n",
        "    top5 = sorted(usage.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "    total = sum(usage.values())\n",
        "    print(f'Game {gid}: {[(e, f\"{c/total:.1%}\") for e, c in top5]}')\n",
        "\n",
        "print()\n",
        "for i in range(3):\n",
        "    for j in range(i+1, 3):\n",
        "        top_i = set(e for e, _ in sorted(expert_usage[i].items(), key=lambda x: x[1], reverse=True)[:10])\n",
        "        top_j = set(e for e, _ in sorted(expert_usage[j].items(), key=lambda x: x[1], reverse=True)[:10])\n",
        "        print(f'Game {i} vs {j}: {len(top_i & top_j)}/10 experts overlap')"
      ],
      "metadata": {"id": "analysis"},
      "execution_count": null,
      "outputs": []
    }
  ]
}
